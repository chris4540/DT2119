{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-2c517958d26a>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-2c517958d26a>\"\u001b[1;36m, line \u001b[1;32m21\u001b[0m\n\u001b[1;33m    def mspec(samples, winlen = 400, winshift = 200, preempcoeff=0.97, nfft=512, samplingrate=20000)\u001b[0m\n\u001b[1;37m                                                                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm,mlab\n",
    "from more_itertools import windowed\n",
    "from scipy.signal import *\n",
    "from scipy.fftpack import fft\n",
    "from tools import trfbank\n",
    "from scipy.fftpack.realtransforms import dct\n",
    "from tools import lifter, todigit2labels\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import sys\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "np.random.seed(19860330)\n",
    "# import more_itertools.windowed\n",
    "\n",
    "# DT2119, Lab 1 Feature Extraction\n",
    "\n",
    "# Function given by the exercise ----------------------------------\n",
    "\n",
    "def mspec(samples, winlen = 400, winshift = 200, preempcoeff=0.97, nfft=512, samplingrate=20000)\n",
    "    \"\"\"Computes Mel Filterbank features.\n",
    "\n",
    "    Args:\n",
    "        samples: array of speech samples with shape (N,)\n",
    "        winlen: lenght of the analysis window\n",
    "        winshift: number of samples to shift the analysis window at every time step\n",
    "        preempcoeff: pre-emphasis coefficient\n",
    "        nfft: length of the Fast Fourier Transform (power of 2, >= winlen)\n",
    "        samplingrate: sampling rate of the original signal\n",
    "\n",
    "    Returns:\n",
    "        N x nfilters array with mel filterbank features (see trfbank for nfilters)\n",
    "    \"\"\"\n",
    "    frames = enframe(samples, winlen, winshift)\n",
    "    preemph = preemp(frames, preempcoeff)\n",
    "    windowed = windowing(preemph)\n",
    "    spec = powerSpectrum(windowed, nfft)\n",
    "    return logMelSpectrum(spec, samplingrate)\n",
    "\n",
    "def mfcc(samples, winlen = 400, winshift = 200, preempcoeff=0.97, nfft=512, nceps=13, samplingrate=20000, liftercoeff=22):\n",
    "    \"\"\"Computes Mel Frequency Cepstrum Coefficients.\n",
    "\n",
    "    Args:\n",
    "        samples: array of speech samples with shape (N,)\n",
    "        winlen: lenght of the analysis window\n",
    "        winshift: number of samples to shift the analysis window at every time step\n",
    "        preempcoeff: pre-emphasis coefficient\n",
    "        nfft: length of the Fast Fourier Transform (power of 2, >= winlen)\n",
    "        nceps: number of cepstrum coefficients to compute\n",
    "        samplingrate: sampling rate of the original signal\n",
    "        liftercoeff: liftering coefficient used to equalise scale of MFCCs\n",
    "\n",
    "    Returns:\n",
    "        N x nceps array with lifetered MFCC coefficients\n",
    "    \"\"\"\n",
    "    mspec = mspec(samples, winlen, winshift, preempcoeff, nfft, samplingrate)\n",
    "    ceps = cepstrum(mspec, nceps)\n",
    "    return lifter(ceps, liftercoeff)\n",
    "\n",
    "# Functions to be implemented ----------------------------------\n",
    "\n",
    "def enframe(samples, winlen, winshift):\n",
    "    \"\"\"\n",
    "    Slices the input samples into overlapping windows.\n",
    "\n",
    "    Args:\n",
    "        winlen: window length in samples.\n",
    "        winshift: shift of consecutive windows in samples\n",
    "    Returns:\n",
    "        numpy array [N x winlen], where N is the number of windows that fit\n",
    "        in the input signal\n",
    "    \"\"\"\n",
    "    return np.asarray(list(windowed(samples, winlen, step=winshift, fillvalue=0)))\n",
    "    \n",
    "def preemp(input, p=0.97):\n",
    "    \"\"\"\n",
    "    Pre-emphasis filter.\n",
    "\n",
    "    Args:\n",
    "        input: array of speech frames [N x M] where N is the number of frames and\n",
    "               M the samples per frame\n",
    "        p: preemhasis factor (defaults to the value specified in the exercise)\n",
    "\n",
    "    Output:\n",
    "        output: array of pre-emphasised speech samples\n",
    "    Note (you can use the function lfilter from scipy.signal)\n",
    "    \"\"\"\n",
    "    A = [1]\n",
    "    B = [1, -p]\n",
    "    return lfilter(B,A, input, axis=1)\n",
    "\n",
    "def windowing(input):\n",
    "    \"\"\"\n",
    "    Applies hamming window to the input frames.\n",
    "\n",
    "    Args:\n",
    "        input: array of speech samples [N x M] where N is the number of frames and\n",
    "               M the samples per frame\n",
    "    Output:\n",
    "        array of windoed speech samples [N x M]\n",
    "    Note (you can use the function hamming from scipy.signal, include the sym=0 option\n",
    "    if you want to get the same results as in the example)\n",
    "    \"\"\"\n",
    "    #The amount of samples in one frame\n",
    "    frame_length = 400\n",
    "    return input * hamming(frame_length, sym=False)\n",
    "\n",
    "def powerSpectrum(input, nfft):\n",
    "    \"\"\"\n",
    "    Calculates the power spectrum of the input signal, that is the square of the modulus of the FFT\n",
    "\n",
    "    Args:\n",
    "        input: array of speech samples [N x M] where N is the number of frames and\n",
    "               M the samples per frame\n",
    "        nfft: length of the FFT\n",
    "    Output:\n",
    "        array of power spectra [N x nfft]\n",
    "    Note: you can use the function fft from scipy.fftpack\n",
    "    \"\"\"\n",
    "    ps = np.abs(fft(input, nfft))**2\n",
    "    return ps    \n",
    "  \n",
    "\n",
    "def logMelSpectrum(input, samplingrate):\n",
    "    \"\"\"\n",
    "    Calculates the log output of a Mel filterbank when the input is the power spectrum\n",
    "\n",
    "    Args:\n",
    "        input: array of power spectrum coefficients [N x nfft] where N is the number of frames and\n",
    "               nfft the length of each spectrum\n",
    "        samplingrate: sampling rate of the original signal (used to calculate the filterbank shapes)\n",
    "    Output:\n",
    "        array of Mel filterbank log outputs [N x nmelfilters] where nmelfilters is the number\n",
    "        of filters in the filterbank\n",
    "    Note: use the trfbank function provided in lab1_tools.py to calculate the filterbank shapes and\n",
    "          nmelfilters\n",
    "    \"\"\"\n",
    "    NFFT = input.shape[1]\n",
    "    return np.log(input.dot(trfbank(samplingrate, NFFT).T))\n",
    "\n",
    "def cepstrum(input, nceps):\n",
    "    \"\"\"\n",
    "    Calulates Cepstral coefficients from mel spectrum applying Discrete Cosine Transform\n",
    "\n",
    "    Args:\n",
    "        input: array of log outputs of Mel scale filterbank [N x nmelfilters] where N is the\n",
    "               number of frames and nmelfilters the length of the filterbank\n",
    "        nceps: number of output cepstral coefficients\n",
    "    Output:\n",
    "        array of Cepstral coefficients [N x nceps]\n",
    "    Note: you can use the function dct from scipy.fftpack.realtransforms\n",
    "    \"\"\"\n",
    "    return dct(input, type=2, axis=1, norm='ortho')[:,:nceps]\n",
    "\n",
    "def plot_features(data):\n",
    "    # NOW DO FOR ALL DATA\n",
    "    plt.figure(1)\n",
    "    plt.title('lifted cosine transform')\n",
    "    c = 1\n",
    "    for d in data:\n",
    "        if d['digit']=='4':\n",
    "            print(d['gender'])\n",
    "            plt.subplot(410+c)\n",
    "            mfcc_data = mfcc(d['samples'])\n",
    "            plt.pcolormesh(mfcc_data.T, cmap=cmap)\n",
    "#             plt.plot(mfcc_data)\n",
    "            print(mfcc_data.shape)\n",
    "            c+=1\n",
    "    plt.figure(2)\n",
    "    c = 1\n",
    "    j= 1\n",
    "    for d in data:\n",
    "        if d['digit']=='4':\n",
    "            print(d['gender'])\n",
    "            plt.subplot(410+c)\n",
    "            mfcc_data = mfcc(d['samples'])\n",
    "            print(mfcc_data.shape)\n",
    "            plt.plot(mfcc_data[:,7])\n",
    "            c+=1\n",
    "    plt.show()\n",
    "\n",
    "def concatenate_data(data):\n",
    "    utterances = np.empty((0, 13))\n",
    "    for d in data:\n",
    "        utterances = np.concatenate((utterances, mfcc(d['samples'])), axis=0)\n",
    "    return utterances\n",
    "\n",
    "def correlations(data, sampling_rate=20000, lift=False):\n",
    "    utterances = np.empty((0,13))\n",
    "    for d in data:\n",
    "        if not lift:\n",
    "            frames = enframe(d['samples'], 400, 200)\n",
    "            preemph = preemp(frames, 0.97)\n",
    "            windowed = windowing(preemph)\n",
    "            spec = powerSpectrum(windowed, 512)\n",
    "            mspec = logMelSpectrum(spec, sampling_rate)\n",
    "            ceps = cepstrum(mspec, 13)\n",
    "            utterances = np.concatenate((utterances, mspec),axis=0)\n",
    "        else:\n",
    "            utterances = np.concatenate((utterances, mfcc(d['samples'])),axis=0)\n",
    "    return np.corrcoef(utterances.T)\n",
    "\n",
    "def plot_cov(cov_mat):\n",
    "    print(cov_mat.shape)\n",
    "    cmap = plt.get_cmap('jet')\n",
    "    plt.pcolormesh(cov_mat, cmap=cmap)\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.xlabel('features')\n",
    "    plt.ylabel('features')\n",
    "    plt.axis([0,12,12,0])\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "def dtw(x, y, dist):\n",
    "    \"\"\"Dynamic Time Warping.\n",
    "\n",
    "    Args:\n",
    "        x, y: arrays of size NxD and MxD respectively, where D is the dimensionality\n",
    "              and N, M are the respective lenghts of the sequences\n",
    "        dist: distance function (can be used in the code as dist(x[i], y[j]))\n",
    "\n",
    "    Outputs:\n",
    "        d: global distance between the sequences (scalar) normalized to len(x)+len(y)\n",
    "        LD: local distance between frames from x and y (NxM matrix)\n",
    "        AD: accumulated distance between frames of x and y (NxM matrix)\n",
    "        path: best path thtough AD\n",
    "\n",
    "    Note that you only need to define the first output for this exercise.\n",
    "    \"\"\"\n",
    "    N = x.shape[0]\n",
    "    M = y.shape[0]\n",
    "    global_dist = 0\n",
    "    LD = np.zeros((N, M))\n",
    "    AD = np.zeros((N, M))\n",
    "    path_mat = []\n",
    "    # Initialize the dynamic programming algorithm\n",
    "    # Start out by filling a matrix of local distance values\n",
    "    # between each frame.\n",
    "    for i, x_frame in enumerate(x):\n",
    "        for j, y_frame in enumerate(y):\n",
    "            LD[i, j] = dist(x_frame, y_frame)\n",
    "\n",
    "    nrows, ncols = AD.shape\n",
    "    # set first row\n",
    "    for row in range(1,nrows):\n",
    "        AD[row,0] = AD[row-1,0]+LD[row,0]\n",
    "    # set first col\n",
    "    for col in range(1,ncols):\n",
    "        AD[0,col] = AD[0,col-1] + LD[0,col]\n",
    "\n",
    "    for row in range(1, nrows): # Start from 1 to avoid out of bounds\n",
    "        for col in range(1, ncols):\n",
    "            minimum_dist = LD[row, col] + min(AD[row, col-1],   # To the left\n",
    "                                              AD[row-1, col],   # Above\n",
    "                                              AD[row-1, col-1]) # The diagonal\n",
    "            AD[row, col] = minimum_dist\n",
    "\n",
    "    backtracking = True\n",
    "    i, j = nrows-1, ncols-1\n",
    "    path_mat.append((i,j))\n",
    "    while backtracking:\n",
    "        min_dist =  min(AD[i, j-1],\n",
    "                        AD[i-1, j],\n",
    "                        AD[i-1, j-1])\n",
    "        min_idx = np.where(AD==min_dist)\n",
    "        i, j = min_idx[0][0], min_idx[1][0]\n",
    "        path_mat.append((i,j))\n",
    "        if i == 0 and j == 0:\n",
    "            backtracking = False\n",
    "\n",
    "    global_dist = AD[nrows-1,ncols-1] / (len(x) + len(y))\n",
    "    return LD, AD, path_mat, global_dist\n",
    "\n",
    "def euclidean(x, y):\n",
    "    return np.sqrt(np.sum((x - y)**2))\n",
    "\n",
    "def get_global_dist(data):\n",
    "    N = data.shape[0]\n",
    "    GD = np.zeros((N,N))\n",
    "    row, col = GD.shape\n",
    "    for i in range(row):\n",
    "        x = mfcc(data[i]['samples'])\n",
    "        for j in range(col):\n",
    "            y = mfcc(data[j]['samples'])\n",
    "            _, _, _, GD[i,j] = dtw(x,y,euclidean)\n",
    "    return GD\n",
    "\n",
    "def select_number(data, digit):\n",
    "    X_test = np.empty((0, 13))\n",
    "    c = 0\n",
    "    for d in data:\n",
    "        if d['digit'] == digit and d['speaker'] == 'bm' and d['repetition'] == 'a' and d['gender'] == 'man':\n",
    "            print(d['digit'], d['speaker'], d['repetition'], d['gender'])\n",
    "            X_test = np.concatenate((X_test, mfcc(d['samples'])), axis=0)\n",
    "            c+=1\n",
    "#         elif d['digit'] == digit and d['speaker'] == 'ew' and d['repetition'] == 'b':\n",
    "#             print(d['digit'], d['speaker'], d['repetition'], d['gender'])\n",
    "#             X_test = np.concatenate((X_test, mfcc(d['samples'])), axis=0)\n",
    "\n",
    "    return X_test\n",
    "\n",
    "def main():\n",
    "    cmap = plt.get_cmap('jet')\n",
    "    # print(\"Hello, world!\")\n",
    "    example = np.load('data/lab1_example.npz')['example'].item()\n",
    "\n",
    "    # Data contains array of dictionaries\n",
    "    data = np.load('data/lab1_data.npz')['data']\n",
    "\n",
    "    # ***** GAUSSIAN MIXTURE MODEL *****\n",
    "\n",
    "    # Get test data for one digit\n",
    "    test_data_7 = select_number(data, '7')\n",
    "#     test_data = np.concatenate((test_data,select_number(data, '9')))\n",
    "    # Train data on all utterances\n",
    "    mfcc_mat = concatenate_data(data)\n",
    "\n",
    "    components = [4,8,16,32]\n",
    "    for c in components:\n",
    "        # Create model\n",
    "        gmm = GaussianMixture(c, covariance_type='diag',max_iter=1000, verbose=1)\n",
    "        # Train on all data\n",
    "        gmm.fit(mfcc_mat)\n",
    "        # Predict on #7\n",
    "        y_7 = gmm.predict_proba(test_data_7)\n",
    "        y_idx_7 = gmm.predict(test_data_7)\n",
    "        print(y_7.shape)\n",
    "        print(len(y_idx_7))\n",
    "        print('pred idx_7:' + str(y_idx_7))\n",
    "        cov = gmm.covariances_\n",
    "        means = gmm.means_\n",
    "        \n",
    "        import scipy.stats\n",
    "        x_axis=np.arange(-200,200,1)\n",
    "#         fig ,ax = plt.subplots(c,13)\n",
    "        for i in range(c):\n",
    "            for j in range(means.shape[1]):\n",
    "                plt.plot(scipy.stats.norm.pdf(x_axis,means[i,j],cov[i,j]))\n",
    "#                 plt.plot(scipy.stats.norm.pdf(x_axis,mfcc_mat.mean(axis=1),mfcc_mat.var(axis=1)))\n",
    "            plt.show() \n",
    "        print(test_data_7.shape)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
